{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMfI3CxccWK6nQ7UEAkLyV8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"UIP2YVAen41G","executionInfo":{"status":"ok","timestamp":1685491189809,"user_tz":180,"elapsed":172,"user":{"displayName":"Vaasudevan Srinivasan","userId":"15487097235806161418"}},"outputId":"b57ccf7a-933d-41ad-ee79-9aef651ed93d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.0.1+cu118'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}],"source":["from sklearn.model_selection import train_test_split\n","import torch\n","from torch import nn\n","\n","torch.__version__"]},{"cell_type":"markdown","source":["# 37. Creating a Dataset with Linear Regression"],"metadata":{"id":"hxHi7KBGGPmH"}},{"cell_type":"code","source":["weight, bias = 0.7, 0.3\n","\n","X = torch.arange(0, 1, 0.02).unsqueeze(dim=1)\n","y = weight * X + bias\n","\n","x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","x_train.shape, x_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y4zlde4QGV21","executionInfo":{"status":"ok","timestamp":1685492341708,"user_tz":180,"elapsed":147,"user":{"displayName":"Vaasudevan Srinivasan","userId":"15487097235806161418"}},"outputId":"fefb273b-9f35-4546-b2e0-3dda40d58d0c"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([40, 1]), torch.Size([10, 1]))"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["# 40. Creating our first PyTorch Model"],"metadata":{"id":"KCHv-k-fpfOJ"}},{"cell_type":"code","source":["class LinearRegressionModel(nn.Module):\n","\n","    def __init__(self):\n","\n","        super().__init__()\n","\n","        self.weights = nn.Parameter(\n","            torch.randn(1, requires_grad=True, dtype=torch.float32))\n","\n","        self.bias = nn.Parameter(\n","            torch.randn(1, requires_grad=True, dtype=torch.float32))\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","\n","        \"\"\" Linear Regression Formula Forward Method \"\"\"\n","\n","        return self.weights * x + self.bias"],"metadata":{"id":"QbDd90NPpnL_","executionInfo":{"status":"ok","timestamp":1685490600310,"user_tz":180,"elapsed":151,"user":{"displayName":"Vaasudevan Srinivasan","userId":"15487097235806161418"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# 43. Checking out the Internals of PyTorch Model"],"metadata":{"id":"HVxt8VFLEQPd"}},{"cell_type":"code","source":["torch.manual_seed(42)\n","\n","model_0 = LinearRegressionModel()\n","list(model_0.parameters())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nw_1IIqbEUMw","executionInfo":{"status":"ok","timestamp":1685493130760,"user_tz":180,"elapsed":162,"user":{"displayName":"Vaasudevan Srinivasan","userId":"15487097235806161418"}},"outputId":"1d498659-5a57-4af7-ec4e-39101e54ac35"},"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Parameter containing:\n"," tensor([0.3367], requires_grad=True),\n"," Parameter containing:\n"," tensor([0.1288], requires_grad=True)]"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["model_0.state_dict()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VBW0CoH0Eb2f","executionInfo":{"status":"ok","timestamp":1685493133532,"user_tz":180,"elapsed":164,"user":{"displayName":"Vaasudevan Srinivasan","userId":"15487097235806161418"}},"outputId":"16eff117-850c-491e-b85d-f60ef259d5d9"},"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/plain":["OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])"]},"metadata":{},"execution_count":54}]},{"cell_type":"markdown","source":["# 44. Making Predictions using Inference Mode"],"metadata":{"id":"awFAkqEJFqJm"}},{"cell_type":"code","source":["# Disables tracking all the gradient values\n","# PyTorch will track fewer values\n","\n","with torch.inference_mode():  # torch.no_grad()\n","    y_preds = model_0(x_test)\n","\n","y_preds"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_B-SO2MwGB_P","executionInfo":{"status":"ok","timestamp":1685491240359,"user_tz":180,"elapsed":192,"user":{"displayName":"Vaasudevan Srinivasan","userId":"15487097235806161418"}},"outputId":"d6a99f7c-1ab0-48b8-ad73-9afed37a65a3"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.3443],\n","        [0.2770],\n","        [0.2029],\n","        [0.1490],\n","        [0.3982],\n","        [0.3510],\n","        [0.4453],\n","        [0.3241],\n","        [0.4251],\n","        [0.3039]])"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["# 46. Setting up an Optimizer and Loss Function"],"metadata":{"id":"O6Jcd8AQGzgq"}},{"cell_type":"code","source":["loss_fn = nn.L1Loss()\n","optim = torch.optim.SGD(model_0.parameters(), lr=0.01)"],"metadata":{"id":"CUiuK4wpIpM2","executionInfo":{"status":"ok","timestamp":1685493141340,"user_tz":180,"elapsed":160,"user":{"displayName":"Vaasudevan Srinivasan","userId":"15487097235806161418"}}},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":["# 48. PyTorch Training Loop"],"metadata":{"id":"Zxuim1j_JU2p"}},{"cell_type":"code","source":["epochs = 100\n","\n","for epoch in range(epochs):\n","\n","    model_0.train()\n","\n","    # 1. Forward Pass\n","    y_pred = model_0(x_train)\n","\n","    # 2. Calculate the loss\n","    loss = loss_fn(y_pred, y_train)\n","\n","    # 3. Zero the gradients of the optimizer\n","    optim.zero_grad()\n","\n","    # 4. Perform Backpropagation\n","    loss.backward()\n","\n","    # 5. Progress / step the optimizer (gradient descent)\n","    optim.step()\n","\n","    model_0.eval()\n","\n","    if epoch % 10 == 0:\n","\n","        with torch.inference_mode():\n","            test_pred = model_0(x_test)\n","            test_loss = loss_fn(test_pred, y_test)\n","\n","        print(f'{epoch=} {loss=} {test_loss=}')\n","        print(model_0.state_dict())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CTYOJWVFJXty","executionInfo":{"status":"ok","timestamp":1685493144253,"user_tz":180,"elapsed":181,"user":{"displayName":"Vaasudevan Srinivasan","userId":"15487097235806161418"}},"outputId":"7fb8ec86-03b5-4b8e-ea79-b2bc30c82977"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch=0 loss=tensor(0.3679, grad_fn=<MeanBackward0>) test_loss=tensor(0.2628)\n","OrderedDict([('weights', tensor([0.3421])), ('bias', tensor([0.1388]))])\n","epoch=10 loss=tensor(0.2386, grad_fn=<MeanBackward0>) test_loss=tensor(0.1475)\n","OrderedDict([('weights', tensor([0.3963])), ('bias', tensor([0.2388]))])\n","epoch=20 loss=tensor(0.1139, grad_fn=<MeanBackward0>) test_loss=tensor(0.0470)\n","OrderedDict([('weights', tensor([0.4502])), ('bias', tensor([0.3348]))])\n","epoch=30 loss=tensor(0.0561, grad_fn=<MeanBackward0>) test_loss=tensor(0.0424)\n","OrderedDict([('weights', tensor([0.4968])), ('bias', tensor([0.3878]))])\n","epoch=40 loss=tensor(0.0430, grad_fn=<MeanBackward0>) test_loss=tensor(0.0523)\n","OrderedDict([('weights', tensor([0.5278])), ('bias', tensor([0.3998]))])\n","epoch=50 loss=tensor(0.0382, grad_fn=<MeanBackward0>) test_loss=tensor(0.0495)\n","OrderedDict([('weights', tensor([0.5481])), ('bias', tensor([0.3923]))])\n","epoch=60 loss=tensor(0.0337, grad_fn=<MeanBackward0>) test_loss=tensor(0.0445)\n","OrderedDict([('weights', tensor([0.5668])), ('bias', tensor([0.3823]))])\n","epoch=70 loss=tensor(0.0291, grad_fn=<MeanBackward0>) test_loss=tensor(0.0398)\n","OrderedDict([('weights', tensor([0.5856])), ('bias', tensor([0.3723]))])\n","epoch=80 loss=tensor(0.0246, grad_fn=<MeanBackward0>) test_loss=tensor(0.0340)\n","OrderedDict([('weights', tensor([0.6037])), ('bias', tensor([0.3613]))])\n","epoch=90 loss=tensor(0.0202, grad_fn=<MeanBackward0>) test_loss=tensor(0.0275)\n","OrderedDict([('weights', tensor([0.6215])), ('bias', tensor([0.3498]))])\n"]}]}]}